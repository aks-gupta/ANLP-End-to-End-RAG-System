{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e16d4d68-9b0d-42a6-acce-9b27e352f6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_data_in_place(file_path):\n",
    "    with open(file_path, 'r') as infile:\n",
    "        lines = infile.readlines()  # Read all lines into a list\n",
    "\n",
    "    cleaned_lines = []\n",
    "    for line in lines:\n",
    "        \n",
    "        # line = line.replace(\"citation needed\", \" \")\n",
    "        line = line.replace(\"â\", \"\")\n",
    "        line = line.replace(\"Â\", \"\")\n",
    "        \n",
    "        line = re.sub(r'\\[\\d+\\]', '', line)\n",
    "\n",
    "        # line = re.sub(r'\\.\\s*Retrieved [A-Za-z]+\\s*\\d{1,2},\\s*\\d{4}', '', line)\n",
    "\n",
    "\n",
    "        # # Remove lines with less than 4 characters\n",
    "        # if len(line.strip()) < 4:\n",
    "        #     continue\n",
    "\n",
    "        # # Remove lines with only [ or ]\n",
    "        # if line.strip() in ['[', ']']:\n",
    "        #     continue\n",
    "\n",
    "        # if line.strip().startswith(\"Take a look\"):\n",
    "        #     continue\n",
    "            \n",
    "        # if line.strip().startswith(\"Coach Mike Tomlin\"):\n",
    "        #     continue\n",
    "\n",
    "\n",
    "        # if line.strip() == \"edit\":\n",
    "        #     continue\n",
    "            \n",
    "        # line = re.sub(r'http\\S+', '', line)\n",
    "\n",
    "        # if re.match(r'^[A-Za-z]+\\s\\d{1,2},$', line.strip()):\n",
    "        #     continue\n",
    "            \n",
    "        # if re.match(r'^\\w+\\s+speaks with the media', line.strip()):\n",
    "        #     continue\n",
    "\n",
    "        \n",
    "        cleaned_lines.append(line)  # Add the cleaned line to the list\n",
    "\n",
    "    with open(file_path, 'w') as outfile:\n",
    "        outfile.writelines(cleaned_lines)  # Write the cleaned lines back to the same file\n",
    "\n",
    "# Example usage\n",
    "clean_data_in_place('../text scraping/sports/pirates_wiki.txt')  # Replace with your file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "962301e5-4163-4108-a943-f3241bb9bc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from ollama import Ollama\n",
    "\n",
    "# # Initialize Ollama model\n",
    "# model = Ollama(model_name='llama 3.2')\n",
    "\n",
    "# def clean_data_with_ollama(text):\n",
    "#     # Define your cleaning prompts\n",
    "#     prompt = f\"Clean the following text: {text}\"\n",
    "    \n",
    "#     # Use Ollama to process the text\n",
    "#     cleaned_text = model.complete(prompt)\n",
    "    \n",
    "#     return cleaned_text\n",
    "\n",
    "# # Example usage\n",
    "# dirty_data = \"This is an example text with [1] citation and less than 4.\"\n",
    "# cleaned_data = clean_data_with_ollama(dirty_data)\n",
    "# print(cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "16e6d6ff-ce5b-4eca-9f9a-f875e2d80cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_event_data(file_path, output_path):\n",
    "    with open(file_path, 'r') as infile:\n",
    "        lines = infile.readlines()\n",
    "\n",
    "    cleaned_data = []\n",
    "    block = []\n",
    "\n",
    "    for line in lines:\n",
    "        # Check if the line starts a new event block\n",
    "        if line.startswith(\"Event:\"):\n",
    "            # If block has \"Event: N/A\", do not add it to cleaned_data\n",
    "            if block and not block[0].startswith(\"Event: N/A\"):\n",
    "                cleaned_data.extend(block)\n",
    "            # Reset block for the new event\n",
    "            block = [line]\n",
    "        else:\n",
    "            # Keep adding lines to the current block\n",
    "            block.append(line)\n",
    "\n",
    "    # Add the last block if it wasn't N/A\n",
    "    if block and not block[0].startswith(\"Event: N/A\"):\n",
    "        cleaned_data.extend(block)\n",
    "\n",
    "    # Write cleaned data to the output file\n",
    "    with open(output_path, 'w') as outfile:\n",
    "        outfile.writelines(cleaned_data)\n",
    "\n",
    "# Example usage\n",
    "input_file = \"./text scraping/pittsburgh-city-events.txt\"\n",
    "output_file = \"./text scraping/pittsburgh-city-events_cleaned.txt\"\n",
    "clean_event_data(input_file, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1dc5bed0-2bc3-4c12-9cb7-ace25697d6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacement completed. Check the output file.\n"
     ]
    }
   ],
   "source": [
    "input_file = './text scraping/sports/penguins_schedule.txt'\n",
    "output_file = './text scraping/sports/penguins_schedule_updated.txt'\n",
    "\n",
    "# Open the input file, read its content, and replace the desired text\n",
    "with open(input_file, 'r', encoding='utf-8') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Replace each occurrence of \"Event: \" with \"Event: Pittsburgh Steelers vs. \"\n",
    "updated_content = content.replace(\"vs Pittsburgh\", \"vs Pittsburgh Penguins\")\n",
    "updated_content = updated_content.replace(\"Pittsburgh vs\", \"Pittsburgh Penguins vs\")\n",
    "\n",
    "# Write the updated content to the output file\n",
    "with open(output_file, 'w', encoding='utf-8') as file:\n",
    "    file.write(updated_content)\n",
    "\n",
    "print(\"Replacement completed. Check the output file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f390cbf5-c0af-412a-88f1-1ae7a641a0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Define input and output file paths\n",
    "input_file_path = './text scraping/sports/pirates_schedule.txt'  # Update this path to your actual file\n",
    "output_file_path = './text scraping/sports/pirates_schedule_updated.txt'\n",
    "\n",
    "# Read the event data from the input file\n",
    "with open(input_file_path, 'r', encoding='utf-8') as input_file:\n",
    "    data = input_file.read()\n",
    "\n",
    "# data = f'''\n",
    "# Event: Pirates at Orioles - Time TBD\n",
    "# Start Date: 02/22/25\n",
    "# End Date: 02/22/25\n",
    "# Start Time: Not available\n",
    "# End Time: Not available\n",
    "# Location: Ed Smith Stadium - Sarasota\n",
    "\n",
    "\n",
    "# Event: Twins at Pirates - Time TBD\n",
    "# Start Date: 02/23/25\n",
    "# End Date: 02/23/25\n",
    "# Start Time: Not available\n",
    "# End Time: Not available\n",
    "# Location: LECOM Park - Bradenton\n",
    "# '''\n",
    "\n",
    "# Split the data into individual events\n",
    "event_strings = data.strip().split('\\n\\n\\n')\n",
    "# print(event_strings)\n",
    "\n",
    "# Initialize a list to hold all valid events\n",
    "valid_events = []\n",
    "\n",
    "# Loop through each event string and extract details\n",
    "for event_string in event_strings:\n",
    "    # print(event_string)\n",
    "    event_details = {}\n",
    "    lines = event_string.split('\\n')\n",
    "    \n",
    "    # Populate the event details\n",
    "    for line in lines:\n",
    "        # print(line)\n",
    "        key, value = line.split(': ', 1)  # Split on the first occurrence of \": \"\n",
    "        # print(key + \"     \" + value)\n",
    "        # event_details[key.strip()] = value.strip()  # Store key-value pairs\n",
    "\n",
    "        if key in ['Event', 'Start Date', 'Location']:\n",
    "            if key == 'Start Date':\n",
    "                event_details['Date'] = value\n",
    "                continue\n",
    "            event_details[key] = value.replace(\" - Time TBD\", \"\")\n",
    "        # print(event_details)\n",
    "    \n",
    "    # Check if any key has \"Not available\" value\n",
    "    # if all(value != \"Not available\" for value in event_details.values()):\n",
    "        # valid_events.append(event_details)  # Append only valid events\n",
    "    valid_events.append(event_details)\n",
    "\n",
    "# Save the valid events list to a JSON file\n",
    "# with open(output_file_path, 'w', encoding='utf-8') as json_file:\n",
    "#     json.dump(valid_events, json_file, indent=4)\n",
    "\n",
    "# print(\"Valid events have been saved to\", output_file_path)\n",
    "\n",
    "with open(output_file_path, 'w') as file:\n",
    "    file.write(str(valid_events))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51d4a0c1-979a-4f65-965c-a1b5c1f4b7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Links removed and cleaned data saved to ../text scraping/EVENTS_WEBSITE_2_cleaned.txt\n"
     ]
    }
   ],
   "source": [
    "input_file = '../text scraping/EVENTS_WEBSITE_2.txt'  # Replace with your actual input file name\n",
    "output_file = '../text scraping/EVENTS_WEBSITE_2_cleaned.txt'  # Output file to save the cleaned data\n",
    "\n",
    "# Open the input file, read its content, and remove lines containing \"Link\"\n",
    "with open(input_file, 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Filter out lines that contain \"Link\"\n",
    "cleaned_lines = [line for line in lines if \"Link\" not in line]\n",
    "\n",
    "# Write the cleaned content to the output file\n",
    "with open(output_file, 'w', encoding='utf-8') as file:\n",
    "    file.writelines(cleaned_lines)\n",
    "\n",
    "print(\"Links removed and cleaned data saved to\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f624e2-a743-4386-88bf-fbe52aa61a54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
